# -*- coding: utf-8 -*-
"""pythonCodeModels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1COKebs8LRm-t7zsttGql4n0DQCotJzkV
"""

### paper: "Temporal-Spatial Convolutional Residual Network for Decoding Attempted Movement Related EEG Signals of Subjects with Spinal Cord Injury"

# Mohammadreza Abbasi Sardari: fcafmohammadreza@aut.ac.ir
# Hamed Mirzabagherian: h.mirabagherian@aut.ac.ir
# Mohammad Bagher Menhaj: menhaj@aut.ac.ir
# Amir Abolfazl Suratgar: a-suratgar@aut.ac.ir


"""# **EEGNet Model**"""

from tensorflow.keras.models import Model
from tensorflow.keras import optimizers
from tensorflow.keras.layers import Dense, Activation, Permute, Dropout , Multiply, Concatenate
from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D
from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D, Conv1D, Add, Reshape
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import SpatialDropout2D
from tensorflow.keras.regularizers import l1_l2
from tensorflow.keras.layers import Input, Flatten
from tensorflow.keras.constraints import max_norm
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Reshape
import numpy as np

def EEGNet(nb_classes=6, Chans = 60, Samples = 800,
             dropoutRate = 0.5, kernLength = 64*2, F1 = 8, 
             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):
    
    if dropoutType == 'SpatialDropout2D':
        dropoutType = SpatialDropout2D
    elif dropoutType == 'Dropout':
        dropoutType = Dropout
    else:
        raise ValueError('dropoutType must be one of SpatialDropout2D '
                         'or Dropout, passed as a string.')
    
    input1   = Input(shape = (1, Chans, Samples))

    ##################################################################
    block1       = Conv2D(F1, (1, kernLength),data_format="channels_first", padding = 'same',
                                   input_shape = (1, Chans, Samples),
                                   use_bias = False)(input1)
    block1       = BatchNormalization(axis = 1)(block1)
    block1       = DepthwiseConv2D((Chans, 1),data_format="channels_first", use_bias = False, 
                                   depth_multiplier = D,
                                   depthwise_constraint = max_norm(1.))(block1)
    block1       = BatchNormalization(axis = 1)(block1)
    block1       = Activation('elu')(block1)
    block1       = AveragePooling2D((1, 8) , data_format="channels_first")(block1)
    block1       = dropoutType(dropoutRate)(block1)
    
    block2       = SeparableConv2D(F2, (1, 50),data_format="channels_first",
                                   use_bias = False, padding = 'same')(block1)
    block2       = BatchNormalization(axis = 1)(block2)
    block2       = Activation('elu')(block2)
    block2       = AveragePooling2D((1, 20 ) , data_format="channels_first")(block2)
    block2       = dropoutType(dropoutRate)(block2)
        
    flatten      = Flatten(name = 'flatten')(block2)
    
    dense        = Dense(nb_classes, name = 'dense', 
                         kernel_constraint = max_norm(norm_rate))(flatten)
    softmax      = Activation('softmax', name = 'softmax')(dense)
    
    model = Model(inputs=input1, outputs=softmax)  
    model.compile(loss='categorical_crossentropy', optimizer='adam',
              metrics = ['accuracy'])
    
    return model

"""# **M-EEGNet Model**"""

def MEEGNet():
    input1 = Input(shape=(1, 60, 800))
    block1 = Conv2D( 30 ,  (1,450) , padding='same',input_shape=(1, 60, 800),kernel_initializer= 'glorot_uniform' ,data_format="channels_first", use_bias='True' )(input1)
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation( 'relu')(block1)
    block1 = Dropout(  0.2 )(block1)
    block1 = DepthwiseConv2D((60, 1), data_format="channels_first", depth_multiplier=24 ,kernel_initializer= 'glorot_uniform' , depthwise_constraint=max_norm(1.), use_bias='True' )(block1)
    block1 = Activation('sigmoid')(block1)
    block1 = AveragePooling2D((1,8) , data_format="channels_first")(block1)
    block1 = Dropout(0.2)(block1)
    block2 = SeparableConv2D(65 , (1,35) ,kernel_initializer= 'he_normal' ,data_format="channels_first", use_bias= 'False' , padding='same')(block1)
    block2 = Activation('linear')(block2)
    block2 = AveragePooling2D( (1,5) , data_format="channels_first")(block2)
    flatten = Flatten(name='flatten')(block2)
    dense = Dense(6, name='dense', kernel_constraint=max_norm(0.25),kernel_initializer= 'he_normal' , use_bias= 'False')(flatten)
    softmax = Activation('softmax', name='softmax')(dense)
    model = Model(inputs=input1, outputs=softmax)    
    model.compile(loss= 'kullback_leibler_divergence',
                  optimizer= 'Nadam' ,
                  metrics=['accuracy'])
    return model

"""# **TSCRNet Model**"""

def TSCRNet():
    input1 = Input(shape=(1, 60, 800))
    F1 = 12
    block1 = Conv2D( F1 , (1,550) , padding='same',input_shape=(1, 60, 800),kernel_initializer= 'glorot_uniform' ,data_format="channels_first", use_bias= 'True' )(input1)
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation( 'relu')(block1)
    block1 = Dropout(0.5)(block1)
    D = 20
    block1 = DepthwiseConv2D((60, 1), data_format="channels_first", depth_multiplier=D ,kernel_initializer= 'he_normal'  , depthwise_constraint=max_norm(1.), use_bias= 'False' )(block1)
    block1 = Activation('linear')(block1)
    P = 2
    block1 = AveragePooling2D( (1,P) , data_format="channels_first")(block1)
    block1 = Dropout(0.4)(block1)
    ###################
    ##########
    a = int(800/P)
    x = Reshape( ( D*F1 , a ), name='reshape1')(block1)

    x = Conv1D( 32 , 1 ,padding='same',data_format='channels_first',dilation_rate=1 , kernel_initializer='glorot_normal'  , use_bias= 'False')(x)
    x = Activation('elu')(x)
    
    x = SeparableConv1D( 32 , 1 , padding='same',data_format='channels_first',dilation_rate=1,kernel_initializer= 'he_normal'  , use_bias='True')(x)
    x = BatchNormalization(axis=1)(x)
    x = Activation( 'relu')(x)
    x = Dropout(0.5)(x)
    
    x = Conv1D( D*F1 ,1,padding='same',data_format='channels_first',dilation_rate=1,kernel_initializer='glorot_normal' ,use_bias='False' )(x)
    x = BatchNormalization(axis=1)(x)
    x = Activation( 'relu')(x) 
    x = Dropout(0.5)(x)

    x = Reshape((D*F1, 1, a) , name='reshape2')(x)
    y = Add()([x,block1])
    y = AveragePooling2D(  (1,5) , data_format="channels_first")(y)

    ######  
    flatten = Flatten(name='flatten')(y)
    dense = Dense(6, name='dense', kernel_constraint=max_norm(0.25),kernel_initializer= 'glorot_uniform' , use_bias='True')(flatten)
    softmax = Activation('softmax', name='softmax')(dense)

    model = Model(inputs=input1, outputs=softmax)    
    model.compile(loss='kullback_leibler_divergence',
                  optimizer= 'Nadam' ,
                  metrics=['accuracy'])
    return model

"""# **TSCIRNet Model**"""

def TSCIRNet():
    input1 = Input(shape=(1, 60, 800))
    F1 = 26
    block1 = Conv2D( F1 , (1,590) , padding='same',input_shape=(1, 60, 800),kernel_initializer='glorot_normal' ,data_format="channels_first", use_bias='True' )(input1)
    block1 = Activation( 'relu')(block1)
    block1 = Dropout(0.4)(block1)
    D = 8
    block1 = DepthwiseConv2D((60, 1), data_format="channels_first", depth_multiplier=D ,kernel_initializer= 'glorot_uniform'  , depthwise_constraint=max_norm(1.), use_bias= 'False' )(block1)
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation('linear')(block1)
    P = 4
    block1 = AveragePooling2D( (1,P) , data_format="channels_first")(block1)
    block1 = Dropout(0.4)(block1)
    
    ##########
    a = int(800/P)
    x = Reshape( ( D*F1 , a ), name='reshape1')(block1)

    x = Conv1D( 90 , 1 ,padding='same',data_format='channels_first',dilation_rate=1 , kernel_initializer= 'he_uniform' , use_bias= 'False')(x)
    x = Activation('elu' )(x)
    x = Dropout(0.2)(x)
    
    x = SeparableConv1D( 16 , 1 , padding='same',data_format='channels_first',dilation_rate=2,kernel_initializer='glorot_uniform' , use_bias='True')(x)
    x = Activation('linear')(x)
    
    x = Conv1D( D*F1 ,1,padding='same',data_format='channels_first',dilation_rate=1,kernel_initializer= 'he_normal'  ,use_bias='True' )(x)
    x = Activation('sigmoid')(x) 
    x = Dropout(0.6)(x)

    x = Reshape((D*F1, 1, a) , name='reshape2')(x)
    y = Add()([x,block1])

    #########  two
    #####
    xx = Reshape( ( D*F1 , a ), name='reshape3')(y)

    xx = Conv1D( 16 , 1 ,padding='same',data_format='channels_first',dilation_rate=2 , kernel_initializer= 'glorot_uniform'  , use_bias= 'False')(xx)
    xx = Activation('elu' )(xx)
    xx = Dropout(0.4)(xx)
    
    xx = SeparableConv1D( 80 , 1 , padding='same',data_format='channels_first',dilation_rate=2,kernel_initializer= 'he_normal'  , use_bias='True')(xx)
    xx = BatchNormalization(axis=1)(xx)
    xx = Activation('elu')(xx)
    xx = Dropout(0.5)(xx)
    
    xx = Conv1D( D*F1 ,1,padding='same',data_format='channels_first',dilation_rate=2,kernel_initializer= 'he_uniform' ,use_bias= 'False' )(xx)
    xx = BatchNormalization(axis=1)(xx)
    xx = Activation('elu' )(xx) 

    xx = Reshape((D*F1, 1, a) , name='reshape4')(xx)
    yy = Add()([xx,y])

    yy = AveragePooling2D(  (1,2)  , data_format="channels_first")(yy)

    ############    
    flatten = Flatten(name='flatten')(yy)
    dense = Dense(6, name='dense', kernel_constraint=max_norm(0.25),kernel_initializer= 'he_normal', use_bias= 'False')(flatten)
    softmax = Activation('softmax', name='softmax')(dense)

    model = Model(inputs=input1, outputs=softmax)    
    model.compile(loss='categorical_crossentropy',
                  optimizer= 'Nadam' ,
                  metrics=['accuracy'])
    return model

"""# **DeepConvNet Model**"""

def DeepConvNet(nb_classes=6 , Chans = 60, Samples = 800,
                dropoutRate = 0.5):
    
    # start the model
    input_main   = Input((1, Chans, Samples))
    block1       = Conv2D(25, (1, 5*2), 
                                 input_shape=(1, Chans, Samples),data_format="channels_first",
                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)
    block1       = Conv2D(25, (Chans, 1),data_format="channels_first",
                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)
    block1       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block1)
    block1       = Activation('elu')(block1)
    block1       = MaxPooling2D(pool_size=(1, 4), strides=(1, 2),data_format="channels_first")(block1)  
    block1       = Dropout(dropoutRate)(block1)
  
    block2       = Conv2D(50, (1, 5*2),data_format="channels_first",
                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)
    block2       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block2)
    block2       = Activation('elu')(block2)
    block2       = MaxPooling2D(pool_size=(1, 4), strides=(1, 2),data_format="channels_first")(block2)   
    block2       = Dropout(dropoutRate)(block2)
    
    block3       = Conv2D(100, (1, 5*2),data_format="channels_first",
                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)
    block3       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block3)
    block3       = Activation('elu')(block3)
    block3       = MaxPooling2D(pool_size=(1, 5), strides=(1, 2),data_format="channels_first")(block3)  
    block3       = Dropout(dropoutRate)(block3)
    
    block4       = Conv2D(200, (1, 5*2),data_format="channels_first",
                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)
    block4       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block4)
    block4       = Activation('elu')(block4)
    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2),data_format="channels_first")(block4)   
    block4       = Dropout(dropoutRate)(block4)
    
    flatten      = Flatten()(block4)
    
    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)
    softmax      = Activation('softmax')(dense)
    
    model = Model(inputs=input_main, outputs=softmax)  
    
    model.compile(loss='categorical_crossentropy', optimizer='adam',
              metrics = ['accuracy'])
    
    return model

"""# **ShallowConvNet Model**"""

def ShallowConvNet(nb_classes=6, Chans = 60, Samples = 800, dropoutRate = 0.5):

    input_main   = Input((1,Chans, Samples))

    block1       = Conv2D(40, (1, 13*2),data_format="channels_first",input_shape=(1,Chans, Samples),
                          kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)
    
    block1       = Conv2D(40, (Chans, 1), use_bias=False,data_format="channels_first",
                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)

    block1       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block1)

    block1       = Activation(square)(block1)

    block1       = AveragePooling2D(pool_size=(1, 80), strides=(1, 7) , data_format="channels_first")(block1)

    block1       = Activation(log)(block1)
    block1       = Dropout(dropoutRate)(block1)
    flatten      = Flatten()(block1)
    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)
    softmax      = Activation('softmax')(dense)

    model = Model(inputs=input_main, outputs=softmax)  
    
    model.compile(loss='categorical_crossentropy', optimizer='adam',
              metrics = ['accuracy'])
    
    return model

"""# **MBEEGSE Model**"""

def squeeze_excite_block (input, ratio=2):
    init = input      
    channel_axis = 1       
    filters = init.shape[channel_axis]   
    se_shape = (1 , 1, filters) 

    se = GlobalAveragePooling2D(data_format="channels_first")(init)  
    se = Reshape(se_shape)(se)  
    se = Dense(filters // ratio, activation='relu')(se)   
    se = Dense(filters, activation='sigmoid')(se)    
    
    se = Reshape((filters, 1, 1))(se)
    x = Multiply()([init, se])
    return x

def EEGNet(input, F1 , f1, dropoutRate):
    Chans = 60
    Samples = 800
    block1 = Conv2D(F1, (1, f1), padding='same',input_shape=(1, 60, 800),data_format="channels_first",use_bias=True)(input)
    block1 = BatchNormalization(axis=1)(block1)
    D = 2     
    block1 = DepthwiseConv2D((60, 1), data_format="channels_first",use_bias=True, depth_multiplier=D, depthwise_constraint=max_norm(1.))(block1) 
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation('elu')(block1) 
    block1 = AveragePooling2D((1, 4),data_format="channels_first")(block1) 
    block1 = Dropout(dropoutRate)(block1)
    
    F2 = F1 *D    
    f2 = 32      
    block1 = SeparableConv2D(F2, (1, f2), data_format="channels_first",use_bias=True, padding='same')(block1)
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation('elu')(block1)
    block1 = AveragePooling2D((1, 8), data_format="channels_first")(block1)
    block1 = Dropout(dropoutRate)(block1)
    return block1

def MBEEGSEmodel():

  input = Input(shape=(1, 60, 800))

  # Branch 1
  y1 = EEGNet(input, F1=4 , f1=160, dropoutRate=0 )    
  x1 = squeeze_excite_block(y1,4)
  x1 = Flatten()(x1)
  output1 = Dense(6,use_bias=True)(x1) 


  # Branch 2
  y2 = EEGNet(input, F1=8 , f1=320, dropoutRate=0.1)       
  x2 = squeeze_excite_block(y2,4)
  x2 = Flatten()(x2)
  output2 = Dense(6, use_bias=True)(x2) 


  # Branch 3
  y3 = EEGNet(input, F1=16 , f1=640, dropoutRate=0.2)     
  x3 = squeeze_excite_block(y3,2)
  x3 = Flatten()(x3)
  output3 = Dense(6,use_bias=True)(x3)     
  
  # Concatenate
  out = Concatenate()([output1, output2, output3])

  out = Flatten()(out)
  out = Dense(6,use_bias=True)(out) 
  output = Activation('softmax')(out)

  model = Model(input, output)
  adam = optimizers.Adam(learning_rate=0.0009)
  model.compile(optimizer= adam , loss='categorical_crossentropy', metrics=['accuracy'])
  return model

"""# **TCNet-Fusion Model**"""

def residualblock (input):   
  input = Reshape(( 48, 12))(input)

  ###
  y = Conv1D( 12 , 4 , padding='causal' ,dilation_rate = 1,data_format= 'channels_first')(input)  
  y = Conv1D( 12 , 4 , padding='causal' , dilation_rate= 2,data_format= 'channels_first')(y)
  y = Conv1D( 12 , 4 , padding='causal' , dilation_rate= 4,data_format= 'channels_first')(y)
  y = BatchNormalization(axis=1)(y)
  y = Activation('elu')(y)
  y = Dropout(0.3)(y)

  ###
  y = Conv1D( 12 , 4 , padding='causal' ,dilation_rate = 1,data_format= 'channels_first')(y)
  y = Conv1D( 12 , 4 , padding='causal' , dilation_rate= 2,data_format= 'channels_first')(y)
  y = Conv1D( 12 , 4 , padding='causal' , dilation_rate= 4,data_format= 'channels_first')(y)
  y = BatchNormalization(axis=1)(y)
  y = Activation('elu')(y)
  y = Dropout(0.3)(y)


  ### optional conv
  x = Conv1D(12,1,padding='same',data_format= 'channels_first')(input)

  out = Add()([x,y])
  
  out = Reshape(( 48, 1, 12))(input)
  return out

def TCNetFusionmodel():
  input = Input(shape=(1, 60, 800))
  x = Conv2D( 24 ,  (1,320) , padding='same',data_format= 'channels_first', input_shape=(1,60, 800))(input)
  x = BatchNormalization(axis=1)(x)

  x = DepthwiseConv2D((60, 1), padding='valid',depth_multiplier=2 ,data_format= 'channels_first' , depthwise_constraint=max_norm(1.))(x)
  x = BatchNormalization(axis=1)(x)
  x = Activation('elu')(x)
  x = AveragePooling2D((1,8), data_format= 'channels_first')(x)
  D1 = Dropout(0.3)(x)

  x = SeparableConv2D(48 , (1,16) ,data_format= 'channels_first', padding='same')(x)
  x = BatchNormalization(axis=1)(x)
  x = Activation('elu')(x)
  x = AveragePooling2D((1,8), data_format= 'channels_first')(x)
  D2 = Dropout(0.3)(x)


  ### TCN
  y = residualblock (input = D2 )
  TC = residualblock (input = y)

  ##
  CONV1 = Concatenate(axis = 1)([TC, D2])
  FC2 = Flatten()(CONV1)

  ###
  FC1 = Flatten()(D1)

  CONV2 = Concatenate()([FC1, FC2])

  output = Dense(6, activation='softmax',  kernel_constraint=max_norm(0.25))(CONV2) 

  model = Model(input, output)
  adam = optimizers.Adam(learning_rate=0.0009)
  model.compile(optimizer= adam , loss='categorical_crossentropy', metrics=['accuracy'])  
  return model

"""# **EEG-TCNet Model**"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.layers import Conv1D,Conv2D, AveragePooling2D,SeparableConv2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Dropout, Add, Lambda,DepthwiseConv2D,Input, Permute

def EEGTCNet(nb_classes = 6,Chans = 60, Samples=800, layers=3, kernel_s=4,filt=12, dropout=0.3, activation='elu', F1=8*2, D=2, kernLength=320, dropout_eeg=0.2):
    input1 = Input(shape = (1,Chans, Samples))
    input2 = Permute((3,2,1))(input1)
    regRate=.25
    numFilters = F1
    F2= numFilters*D

    EEGNet_sep = EEGNet(input_layer=input2,F1=F1,kernLength=kernLength,D=D,Chans=Chans,dropout=dropout_eeg)
    block2 = Lambda(lambda x: x[:,:,-1,:])(EEGNet_sep)
    outs = TCN_block(input_layer=block2,input_dimension=F2,depth=layers,kernel_size=kernel_s,filters=filt,dropout=dropout,activation=activation)
    out = Lambda(lambda x: x[:,-1,:])(outs)
    dense        = Dense(nb_classes, name = 'dense',kernel_constraint = max_norm(regRate))(out)
    softmax      = Activation('softmax', name = 'softmax')(dense)
    
    model = Model(input1, softmax)

    adam = optimizers.Adam(learning_rate = 0.001)   # Adam
    model.compile(optimizer= 'adam' , loss='categorical_crossentropy', metrics=['accuracy']) 

    return model

def EEGNet(input_layer,F1=8,kernLength=32,D=2,Chans=60,dropout=0.2):
    F2= F1*D
    block1 = Conv2D(F1, (kernLength, 1), padding = 'same',data_format='channels_last',use_bias = False)(input_layer)
    block1 = BatchNormalization(axis = -1)(block1)
    block2 = DepthwiseConv2D((1, Chans), use_bias = False, 
                                    depth_multiplier = D,
                                    data_format='channels_last',
                                    depthwise_constraint = max_norm(1.))(block1)
    block2 = BatchNormalization(axis = -1)(block2)
    block2 = Activation('elu')(block2)
    block2 = AveragePooling2D((8,1),data_format='channels_last')(block2)
    block2 = Dropout(dropout)(block2)
    block3 = SeparableConv2D(F2, (16, 1),
                            data_format='channels_last',
                            use_bias = False, padding = 'same')(block2)
    block3 = BatchNormalization(axis = -1)(block3)
    block3 = Activation('elu')(block3)
    block3 = AveragePooling2D((8,1),data_format='channels_last')(block3)
    block3 = Dropout(dropout)(block3)
    return block3

def TCN_block(input_layer,input_dimension,depth,kernel_size,filters,dropout,activation='elu'):
    block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=1,activation='linear',
                   padding = 'causal',kernel_initializer='he_uniform')(input_layer)
    block = BatchNormalization()(block)
    block = Activation(activation)(block)
    block = Dropout(dropout)(block)
    block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=1,activation='linear',
                   padding = 'causal',kernel_initializer='he_uniform')(block)
    block = BatchNormalization()(block)
    block = Activation(activation)(block)
    block = Dropout(dropout)(block)
    if(input_dimension != filters):
        conv = Conv1D(filters,kernel_size=1,padding='same')(input_layer)
        added = Add()([block,conv])
    else:
        added = Add()([block,input_layer])
    out = Activation(activation)(added)
    
    for i in range(depth-1):
        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',
                   padding = 'causal',kernel_initializer='he_uniform')(out)
        block = BatchNormalization()(block)
        block = Activation(activation)(block)
        block = Dropout(dropout)(block)
        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',
                   padding = 'causal',kernel_initializer='he_uniform')(block)
        block = BatchNormalization()(block)
        block = Activation(activation)(block)
        block = Dropout(dropout)(block)
        added = Add()([block, out])
        out = Activation(activation)(added)
        
    return out

"""# **FMBEEGCBAM and MBEEGCBAM Models**"""

from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda
from keras import backend as K
from keras.activations import sigmoid

def cbam_block(cbam_feature, ratio, kernel_size):
	"""Contains the implementation of Convolutional Block Attention Module(CBAM) block.
	As described in https://arxiv.org/abs/1807.06521.
	"""
	
	cbam_feature = channel_attention(cbam_feature, ratio)
	cbam_feature = spatial_attention(cbam_feature, kernel_size)
	return cbam_feature

def channel_attention(input_feature, ratio):
	
	channel_axis = 1 if K.image_data_format() == "channels_first" else -1
	channel = input_feature.shape[channel_axis]  
	
	shared_layer_one = Dense(channel//ratio,
							 activation='relu',
							 kernel_initializer='he_normal',
							 use_bias=True,
							 bias_initializer='zeros')
	shared_layer_two = Dense(channel,
							 kernel_initializer='he_normal',
							 use_bias=True,
							 bias_initializer='zeros')
	
	avg_pool = GlobalAveragePooling2D()(input_feature)    
	avg_pool = Reshape((1,1,channel))(avg_pool)
	assert avg_pool.shape[1:] == (1,1,channel)     
	avg_pool = shared_layer_one(avg_pool)
	assert avg_pool.shape[1:] == (1,1,channel//ratio)   
	avg_pool = shared_layer_two(avg_pool)
	assert avg_pool.shape[1:] == (1,1,channel)     
	
	max_pool = GlobalMaxPooling2D()(input_feature)
	max_pool = Reshape((1,1,channel))(max_pool)
	assert max_pool.shape[1:] == (1,1,channel)     
	max_pool = shared_layer_one(max_pool)
	assert max_pool.shape[1:] == (1,1,channel//ratio)     
	max_pool = shared_layer_two(max_pool)
	assert max_pool.shape[1:] == (1,1,channel)     
	
	cbam_feature = Add()([avg_pool,max_pool])
	cbam_feature = Activation('relu')(cbam_feature)
	
	if K.image_data_format() == "channels_first":
		cbam_feature = Permute((3, 1, 2))(cbam_feature)
	
	return multiply([input_feature, cbam_feature])

def spatial_attention(input_feature , kernel_size):
	#kernel_size = 7
	
	if K.image_data_format() == "channels_first":
		channel = input_feature.shape[1]          
		cbam_feature = Permute((2,3,1))(input_feature)
	else:
		channel = input_feature.shape[-1]          
		cbam_feature = input_feature
	
	avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)
	assert avg_pool.shape[-1] == 1      
	max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)
	assert max_pool.shape[-1] == 1       
	concat = Concatenate(axis=3)([avg_pool, max_pool])
	assert concat.shape[-1] == 2          
	cbam_feature = Conv2D(filters = 1,
					kernel_size=kernel_size,
					strides=1,
					padding='same',
					activation='relu',
					kernel_initializer='he_normal',
					use_bias=False)(concat)	
	assert cbam_feature.shape[-1] == 1    
	
	if K.image_data_format() == "channels_first":
		cbam_feature = Permute((3, 1, 2))(cbam_feature)
		
	return multiply([input_feature, cbam_feature])
		

def EEGNet(input, F1 , f1, dropoutRate):
    block1 = Conv2D(F1, (1, f1), padding='same',input_shape=(1, Chans, Samples),data_format="channels_first",use_bias=True)(input)
    block1 = BatchNormalization(axis=1)(block1)
    D = 2   
    block1 = DepthwiseConv2D((Chans, 1), data_format="channels_first",use_bias=True, depth_multiplier=D, depthwise_constraint=max_norm(1.))(block1) 
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation('elu')(block1) 
    block1 = AveragePooling2D((1, 4),data_format="channels_first")(block1) 
    block1 = Dropout(dropoutRate)(block1)
    
    F2 = F1*D     
    f2 = 32     
    block1 = SeparableConv2D(F2, (1, f2), data_format="channels_first",use_bias=True, padding='same')(block1)
    block1 = BatchNormalization(axis=1)(block1)
    block1 = Activation('elu')(block1)
    block1 = AveragePooling2D((1, 8), data_format="channels_first")(block1)
    block1 = Dropout(dropoutRate)(block1)
    return block1

#########   MBEEGCBAM  Model

def MBEEGCBAMmodel():
  Chans = 60
  Samples = 800
  input = Input( shape=(1,  60,  800))

  # Branch 1
  y1 = EEGNet(input, F1= 4 , f1=160, dropoutRate=0 ) 
  x1 = cbam_block(y1, ratio=2, kernel_size=2)
  x1 = Flatten()(x1)
  output1 = Dense(6 )(x1) 


  # Branch 2
  y2 = EEGNet(input, F1= 8 , f1=320, dropoutRate=0.1)      
  x2 = cbam_block(y2, ratio=8, kernel_size=4)
  x2 = Flatten()(x2)
  output2 = Dense(6 )(x2) 


  # Branch 3
  y3 = EEGNet(input, F1= 16 , f1=640, dropoutRate=0.2)      
  x3 =  cbam_block(y3, ratio=8, kernel_size=2)
  x3 = Flatten()(x3)
  output3 = Dense(6 )(x3) 

  out = Concatenate()([output1, output2, output3])

  out = Flatten()(out)
  out = Dense(6 )(out)   
  output = Activation('softmax')(out)

  model = Model(input, output)
  adam = optimizers.Adam(learning_rate = 0.0009)  
  model.compile(optimizer= adam , loss='categorical_crossentropy', metrics=['accuracy']) 
  return model

#### FMBEEGCBAM  Model 


def FMBEEGCBAMmodel():
  Chans = 60
  Samples = 800
  input = Input(shape=(1, Chans, Samples))

  # Branch 1
  y1 = EEGNet(input, F1=4 , f1=160, dropoutRate=0 )  
  x1 = cbam_block(y1, ratio=2, kernel_size=2)

  # Branch 2
  y2 = EEGNet(input, F1=8 , f1=320, dropoutRate=0.1  )     
  x2 = cbam_block(y2, ratio=8, kernel_size=4)

  # Branch 3
  y3 = EEGNet(input, F1=16 , f1=640, dropoutRate=0.2 )     
  x3 =  cbam_block(y3, ratio=8, kernel_size=2)


  FC2 = Concatenate(axis=1)([x1, x2, x3])
  FC2 = Flatten()(FC2)
  FC2 = Dense(6 )(FC2) 

  FC1 = Concatenate(axis=1)([y1, y2, y3])
  FC1 = Flatten()(FC1)
  FC1 = Dense(6)(FC1) 

  output = Concatenate(axis=1)([FC1, FC2])
  output = Dense(6 )(output) 
  output = Activation('softmax')(output)

  model = Model(input, output)

  adam = optimizers.Adam(learning_rate=0.0009)
  model.compile(optimizer= adam , loss='categorical_crossentropy', metrics=['accuracy'])   

  return model
